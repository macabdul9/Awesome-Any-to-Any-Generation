# Awesome-Any-to-Any-Generation
This repository is dedicated to showcasing state-of-the-art techniques and implementations of any-to-any generative models, which are capable of generating any modality (audio/speech, image/vision, text) from any modality (audio/speech, image/vision, text) as input.

**Models**
1. AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling [Paper](https://arxiv.org/abs/2402.12226)
2. CoDI: Any-to-Any Generation via Composable Diffusion [Paper](https://arxiv.org/abs/2305.11846)
3. CoDi2: In-Context, Interleaved, and Interactive Any-to-Any Generation [Paper](https://arxiv.org/abs/2311.18775)
4. 4M: Massively Multimodal Masked Modeling [Paper](https://arxiv.org/abs/2312.06647)
5. 4M-21: An Any-to-Any Vision Model for Tens of Tasks and Modalities [Paper](https://arxiv.org/abs/2406.09406)
6. C3Net: Compound Conditioned ControlNet for Multimodal Content Generation [Paper](https://arxiv.org/abs/2311.17951)
7. C3LLM: Conditional Multimodal Content Generation Using Large Language Models [Paper](https://arxiv.org/abs/2405.16136)
8. Visual Echoes: A Simple Unified Transformer for Audio-Visual Generation [Paper](https://arxiv.org/abs/2405.14598)
9. NExT-GPT: Any-to-Any Multimodal LLM [Paper](https://arxiv.org/abs/2309.05519)
10. Unified-IO: A Unified Model for Vision, Language, and Multi-Modal Tasks [Paper](https://arxiv.org/abs/2206.08916)
11. Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision, Language, Audio, and Action [Paper](https://arxiv.org/abs/2312.17172)
13. UGen: Multi-modal Music Understanding and Generation with the Power of Large Language Models [Paper](https://arxiv.org/abs/2311.11255)
14. MM-LLMs: Recent Advances in MultiModal Large Language Models [Paper](https://arxiv.org/abs/2401.13601)
15. ModaVerse: Efficiently Transforming Modalities with LLMs [Paper](https://arxiv.org/abs/2401.06395)
16. Brain-Conditional Multimodal Synthesis: A Survey and Taxonomy [Paper](https://arxiv.org/abs/2401.00430)
17. Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers[Paper](https://arxiv.org/abs/2405.05945)
18. WorldGPT: Empowering LLM as Multimodal World Model [Paper](https://arxiv.org/abs/2404.18202)
19. Teal: Tokenize and embed all for multi-modal large language mode [Paper](https://arxiv.org/pdf/2311.04589)
20. Chatillusion: Efficient-aligning interleaved generation ability with visual instruction model [Paper](https://arxiv.org/pdf/2311.17963)
21. “Codi-2: In-context, interleaved, and interactive any-to-any generation [Paper](https://arxiv.org/pdf/2311.18775)
22. SEED-LLaMA: Making LLaMA SEE and Draw with SEED Tokenizer [Paper](https://arxiv.org/abs/2310.01218)



 **At least Two Modalities (Out of Audio, Image, and Text)**
 1. Seeing and Hearing: Open-domain Visual-Audio Generation with Diffusion Latent Aligners [Paper](https://arxiv.org/abs/2402.17723)
 2. MULTI-MODAL LATENT DIFFUSION [Paper][https://arxiv.org/abs/2306.04445)
 3. EasyGen: Easing Multimodal Generation with BiDiffuser and LLMs [Paper](https://arxiv.org/pdf/2310.08949)
 4. Generative Visual Instruction Tuning [Paper](https://arxiv.org/abs/2406.11262)
 5. Multimodal Foundation Models: From Specialists to General-Purpose Assistants [Paper](https://arxiv.org/abs/2309.10020)
 6. Generating Images with Multimodal Language Models [Paper](https://arxiv.org/abs/2305.17216)
 7. Deep cross-modal audio-visual generation [Paper](https://dl.acm.org/doi/abs/10.1145/3126686.3126723?casa_token=AIAYcMcVdNYAAAAA:TrxxDnFlaJN_bu7g26blt70YvBy7j7c09g9BiSbCqCIvrBNxjhBbHPrbtX_RiHPsQfeavUWQDktC)
 8. Cmcgan: A uniform framework for cross-modal visual-audio mutual generation [Paper](https://ojs.aaai.org/index.php/AAAI/article/download/12329/12188)
 9. Generating images with multimodal language models [Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/43a69d143273bd8215578bde887bb552-Paper-Conference.pdf
 10.  Seed-x: Multimodal models with unified multi-granularity comprehension and generation [Paper](https://arxiv.org/pdf/2404.14396)
20. Videopoet:A large language model for zero-shot video generation [Paper](https://arxiv.org/pdf/2312.14125)
21. Videodirectorgpt: Consistent multi-scene video generation via llm-guided planning[Paper](https://arxiv.org/pdf/2309.15091)
22. SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities [Paper](https://arxiv.org/pdf/2305.11000)
23. AudioPaLM: A Large Language Model That Can Speak and Listen [Paper](https://arxiv.org/pdf/2306.12925)
24. LauraGPT: Listen, Attend, Understand, and Regenerate Audio with GPT [Paper](https://arxiv.org/pdf/2310.04673)
25. SALMONN: TOWARDS GENERIC HEARING ABILITIES FOR LARGE LANGUAGE MODELS [Paper](https://arxiv.org/pdf/2310.13289)
26. Qwen-audio: Advancing universal audio understanding via unified large-scale audio-language models [Paper](https://arxiv.org/pdf/2311.07919)
27. Grounding language models to images for multimodal generation [Paper](https://arxiv.org/pdf/2301.13823)
28. Generating images with multimodal language models [Paper](https://arxiv.org/pdf/2305.17216)
29. Generative pretraining in multimodality [Paper](https://arxiv.org/pdf/2307.05222)
30. MINIGPT-5: INTERLEAVED VISION-AND-LANGUAGE GENERATION VIA GENERATIVE VOKENS [Paper](https://arxiv.org/pdf/2310.02239)
31. “Minidalle3: Interactive text to image by prompting large language models[Paper](https://arxiv.org/pdf/2310.07653)


    

**Survey Papers**
1. LLMs Meet Multimodal Generation and Editing: A Survey [Paper](https://arxiv.org/abs/2405.19334)
2. MM-LLMs: Recent Advances in MultiModal Large Language Models [Paper](https://arxiv.org/pdf/2401.13601.pdf?trk=public_post_comment-text)
3. Multimodal foundation models: From specialists to general-purpose assistants [Paper](https://www.nowpublishers.com/article/DownloadSummary/CGV-110)
4. Exploring the reasoning abilities of multimodal large language models (mllms): A comprehensive survey on emerging trends in multimodal reasoning [Paper](https://arxiv.org/pdf/2401.06805)
5. Fairness and bias in multimodal ai: A survey [Paper](https://arxiv.org/pdf/2406.19097)
6. Hallucination of multimodal large language models: A survey [Paper](https://arxiv.org/pdf/2404.18930?trk=public_post_comment-text)
7. The (r) evolution of multimodal large language models: A survey [Paper](https://arxiv.org/pdf/2402.12451)
