# Awesome-Any-to-Any-Generation
This repository is dedicated to showcasing state-of-the-art techniques and implementations of any-to-any generative models, which are capable of generating any modality (audio/speech, image/vision, text) from any modality (audio/speech, image/vision, text) as input.

**Models**
1. AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling [Paper](https://arxiv.org/abs/2402.12226)
2. CoDI: Any-to-Any Generation via Composable Diffusion [Paper](https://arxiv.org/abs/2305.11846)
3. CoDi2: In-Context, Interleaved, and Interactive Any-to-Any Generation [Paper](https://arxiv.org/abs/2311.18775)
4. 4M: Massively Multimodal Masked Modeling [Paper](https://arxiv.org/abs/2312.06647)
5. 4M-21: An Any-to-Any Vision Model for Tens of Tasks and Modalities [Paper](https://arxiv.org/abs/2406.09406)
6. C3Net: Compound Conditioned ControlNet for Multimodal Content Generation [Paper](
7. C3LLM: Conditional Multimodal Content Generation Using Large Language Models [Paper](https://arxiv.org/abs/2405.16136)
8. Visual Echoes: A Simple Unified Transformer for Audio-Visual Generation [Paper](https://arxiv.org/abs/2405.14598)
9. NExT-GPT: Any-to-Any Multimodal LLM [Paper](https://arxiv.org/abs/2309.05519)
10. Unified-IO: A Unified Model for Vision, Language, and Multi-Modal Tasks [Paper](https://arxiv.org/abs/2206.08916)
11. Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision, Language, Audio, and Action [Paper](https://arxiv.org/abs/2312.17172)
13. UGen: Multi-modal Music Understanding and Generation with the Power of Large Language Models [Paper](https://arxiv.org/abs/2311.11255)
14. MM-LLMs: Recent Advances in MultiModal Large Language Models [Paper](https://arxiv.org/abs/2401.13601)
15. ModaVerse: Efficiently Transforming Modalities with LLMs [Paper](https://arxiv.org/abs/2401.06395)
16. Brain-Conditional Multimodal Synthesis: A Survey and Taxonomy [Paper](https://arxiv.org/abs/2401.00430)
17. Lumina-T2X: Transforming Text into Any Modality, Resolution, and Duration via Flow-based Large Diffusion Transformers[Paper](https://arxiv.org/abs/2405.05945)
18. WorldGPT: Empowering LLM as Multimodal World Model [Paper](https://arxiv.org/abs/2404.18202)
19. Seed-x: Multimodal models with unified multi-granularity comprehension and generation [Paper](https://arxiv.org/pdf/2404.14396)
22. Mirasol3B: A Multimodal Autoregressive model for time-aligned and contextual modalities [Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Piergiovanni_Mirasol3B_A_Multimodal_Autoregressive_Model_for_Time-Aligned_and_Contextual_Modalities_CVPR_2024_paper.pdf)
23. Multi_CycGT: A Deep Learning-Based Multimodal Model for Predicting the Membrane Permeability of Cyclic Peptides [Paper](https://pubs.acs.org/doi/pdf/10.1021/acs.jmedchem.3c01611?casa_token=RFFJP9RXqg4AAAAA:9L5zQf0uNPK92T9A9aWH5uUkjvCOVFMHFLjWND8fLJMOBpnvCd9UXoHXWvNCGTKHuRjCktS_Y-xpSmQ)
24. Lumen: Unleashing versatile vision-centric capabilities of large multimodal models [Paper](https://arxiv.org/pdf/2403.07304)
25. Cognitivedog: Large multimodal model based system to translate vision and language into action of quadruped robot [Paper](https://dl.acm.org/doi/pdf/10.1145/3610978.3641080?casa_token=Dj0S9sEYYSIAAAAA:JOEqTmyPF89l8SDSB-EFK2294dQiBaUwa9EBarNbMTb30u60cGKxPYDwqQUKC25WwqLW8Fyrv7hb)
26. nach0: Multimodal natural and chemical languages foundation model [Paper](https://pubs.rsc.org/en/content/articlepdf/2024/sc/d4sc00966e)
27. MammothModa: Multi-Modal Large Language Model [Paper](https://arxiv.org/pdf/2406.18193)
28. Manipllm: Embodied multimodal large language model for object-centric robotic manipulation [Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_ManipLLM_Embodied_Multimodal_Large_Language_Model_for_Object-Centric_Robotic_Manipulation_CVPR_2024_paper.pdf)
29. 

 **At least Two Modalities (Out of Audio, Image, and Text)**
 1. Seeing and Hearing: Open-domain Visual-Audio Generation with Diffusion Latent Aligners [Paper](https://arxiv.org/abs/2402.17723)
 2. MULTI-MODAL LATENT DIFFUSION [Paper][https://arxiv.org/abs/2306.04445)
 3. EasyGen: Easing Multimodal Generation with BiDiffuser and LLMs [Paper](https://arxiv.org/pdf/2310.08949)
 4. Generative Visual Instruction Tuning
 5. Multimodal Foundation Models: From Specialists to General-Purpose Assistants [Paper](https://arxiv.org/abs/2309.10020)
 6. Generating Images with Multimodal Language Models [Paper](https://arxiv.org/abs/2305.17216)
 7. Deep cross-modal audio-visual generation [Paper](https://dl.acm.org/doi/abs/10.1145/3126686.3126723?casa_token=AIAYcMcVdNYAAAAA:TrxxDnFlaJN_bu7g26blt70YvBy7j7c09g9BiSbCqCIvrBNxjhBbHPrbtX_RiHPsQfeavUWQDktC)
 8. Cmcgan: A uniform framework for cross-modal visual-audio mutual generation [Paper](https://ojs.aaai.org/index.php/AAAI/article/download/12329/12188)
 9. Audio-to-image cross-modal generation [Paper](https://ieeexplore.ieee.org/iel7/9891857/9889787/09892863.pdf?casa_token=JqRPI-okJHAAAAAA:HwFVeCgLLlY8hF_1mBWsGR5o46MQS62E5xpu675ZtW6OWPoQciQgkVfLfO2cL6VBHSpAUVg1)
 10. Glamm: Pixel grounding large multimodal model [Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Rasheed_GLaMM_Pixel_Grounding_Large_Multimodal_Model_CVPR_2024_paper.pdf)
 11. Generating images with multimodal language models [Paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/43a69d143273bd8215578bde887bb552-Paper-Conference.pdf)

**Survey Papers**
1. LLMs Meet Multimodal Generation and Editing: A Survey [Paper](https://arxiv.org/abs/2405.19334)
2. MM-LLMs: Recent Advances in MultiModal Large Language Models [Paper](https://arxiv.org/pdf/2401.13601.pdf?trk=public_post_comment-text)
3. Multimodal foundation models: From specialists to general-purpose assistants [Paper](https://www.nowpublishers.com/article/DownloadSummary/CGV-110)
4. Exploring the reasoning abilities of multimodal large language models (mllms): A comprehensive survey on emerging trends in multimodal reasoning [Paper](https://arxiv.org/pdf/2401.06805)
5. Fairness and bias in multimodal ai: A survey [Paper](https://arxiv.org/pdf/2406.19097)
6. Hallucination of multimodal large language models: A survey [Paper](https://arxiv.org/pdf/2404.18930?trk=public_post_comment-text)
7. The (r) evolution of multimodal large language models: A survey [Paper](https://arxiv.org/pdf/2402.12451)
